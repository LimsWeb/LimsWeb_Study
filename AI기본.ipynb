{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "인공지능 > 머신러닝 > 딥러닝\n",
    "\n",
    "머신러닝\n",
    " - 지도학습, 비지도학습, 강화학습\n",
    "\n",
    "데이터마이닝\n",
    " - 실제 대규모 데이터에서 암묵적인, 이전에 알려지지 않은,\n",
    "    잠재적으로 유용할 것 같은 정보를 추출하는 체계적인과정\n",
    "    - 기계학습, 통계학 기법 적용\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca869eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy - 과학 연선을 위해 설계된 다차원 배열처리를 위한 패키지\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "ndim = 배열의 차원\n",
    "shape = 배열의 크기\n",
    "\n",
    "인덱싱, 슬라이싱 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05986bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "-회귀분석 : 변수간의 관계를 분석하고 예측,추정하는 분석\n",
    "    y = a * x + b (a!=0)\n",
    "    \n",
    "-정규분포 : 통계에서 가장 많이 사용하는 확률분포\n",
    "     - 평균에 가까울수록 발생할 확률이 높고, 평균에서 멀어질수록\n",
    "        발생할 확률이 낮게 나타나는 분포\n",
    "        \n",
    "-다중공선성 : 독립변수끼리 영향을 미치지 않는것(비슷한 변수 안겹치게)\n",
    "    \n",
    "  - 선형회귀 : 종속변수y와 한개 이상의 독립변수 x와의 선형 상관관계를\n",
    "      모델링하는 회귀분석 방법\n",
    "  \n",
    "      최소제곱법 : 기울기 a와 절편 b를 구하는 방법\n",
    "      평균제곱근오차(RMSE, Root Mean Squared Error)\n",
    "       - 임의의 선을 그리고 평가한뒤에 조금씩 수정해 가는 방법\n",
    "          - 잘못 그은 선 바로잡기\n",
    "          - 실제갑 * 예측값 을 통해 오차의 합을 구함\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b386a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "경사하강법\n",
    "  - 훌륭한 예측 선 긋기\n",
    "  - 기울기와 절편을 중심으로 각각 미분\n",
    "    - 이를 통해 오차가 최소화되는 지점을 찾는 것\n",
    "      - y_pred = a * x_data +b\n",
    "      - a_diff = 2/len(x_data) * sum(a * x_data + b - y_data) * x_data\n",
    "      - b_diff = 2/len(x_data) * sum(a * x_data + b - y_data)\n",
    "        a = a - lr * a_diff\n",
    "        b = b - lr * b_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb4071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow\n",
    " - 그래프를 만들어서 세션에서 실행하는 과정을 지님\n",
    " - 각지점을 칭하는 노드(operation)와 마치 이동방향같은 에지(tensor)를 통해\n",
    " Tensor의 Flow를 나타냄\n",
    " - 그래프에 operaiton을 추가하고 operation간에 tensor를 전달하여 계산을 징행함\n",
    "\n",
    " - 위 Graph = 모델이며, 이와 함께 Session을 통해 실행할 수 있음.\n",
    " - Session은 원하는 모델을 선택하여 연결하고 일을 시키는 행위를 말함\n",
    "\n",
    " -tf.constant(value, dtype=None, shape=None, name = \"Const\", verify_shape = False)\n",
    "    - value = 상수의 값\n",
    "    - dtype = 상수의 데이터형을 정의\n",
    "    - shape = 행렬의 차원을 정의\n",
    "    - name = 상수의 이름\n",
    "\n",
    " -tf.placeholder\n",
    "  - 먼저 만들고 값을 나중에 정의하는 특이한 자료형\n",
    "  - 만들 때 값말고 type만 지정하고 나중에 지정해 결과를 얻을 수 있음\n",
    "    -placeholder 사용 시 세션을 수행 할 때 feed_dict를 이용해 값을 입력함\n",
    "      - sess.run(optimaizer, (feed_dict={X : x, Y : y})\n",
    "    \n",
    " -tf.variable\n",
    "  - 조건에 따라 값을 바꿔야 할 때 사용\n",
    "  - 변수를 반드시 초기화 해줘야됨\n",
    "    -   with tf.Session() as sess : \n",
    "    -   sess.run(tf.global_variables_initializer())\n",
    " \n",
    "  -Tensor\n",
    "    - 다차원 배열이며 Rank, Shape, Type 속성(구성요소)를 가지고 있음\n",
    "     - Rank = 차원을 의미 (0은 스칼라, 1은 벡터, 2는 행렬, 3이상은 n차원텐서)\n",
    "     - Shape = 텐서가 몇 개의 행과 열을 가지는지의 의미\n",
    "     - Type = 텐서가 담을 수 있는 데이터의 타입을 의미 - tf.float32, tf.int32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF 1.x\n",
    " import tensorflow.compat.v1 as tf\n",
    " tf.disable_v2_behavior()\n",
    "를 통해 1.x 버전 작동 및 2.x 비활성화\n",
    "\n",
    " 세션을 실행하고 진행되며 세션은\n",
    "  with tf.Session() as sess : \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(v))\n",
    "    과\n",
    "  sess = tf.Session()\n",
    "  init = tf.global_variabels_initializer()\n",
    "  sess.run(init)\n",
    "  sess.close() \n",
    "    두가지 방법으로 실행가능함. 전자는 닫아주지 않아도됨(with가 알아서 닫음)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f2f269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (978130037.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    x_data = [x_row[0], for x_row in data]\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### TF 1.x ver 경사하강법\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "data = [[2,81], [4, 93], [6, 91], [4,97]]\n",
    "x_data = [x_row[0], for x_row in data]\n",
    "y_data = [y_row[1], for y_row in data]\n",
    "\n",
    "a = tf.Variable(tf.random_uniform([1], 0 , 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0 , 100, dtype = tf.float64, seed = 0))\n",
    "##### seed, 즉 난수 값을 설정하는 이유는 컴퓨터는 기본적으로 만들 수 없어서임. 이를\n",
    "##### 해결하기 위해 알고리즘을 통해 난수를 생성함, 이 난수를 생성하기위해 쓰는 기초가 되는\n",
    "##### 수를 seed라고 함. 이를 통해 컴퓨터는 같은 패턴의 난수를 생성함(이를 통해 동일한 패턴난수를 생성)\n",
    "\n",
    "y = a * x_data + b\n",
    "\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square( y - y_data)))\n",
    "##### sqrt = 제곱근함수\n",
    "##### tf.reduce_mean은 data들 각각에서 계산된 합의 평균을 구하는 함수\n",
    "#####\n",
    "\n",
    "learning_rate = 0.1\n",
    "##### 학습률이 너무 크거나 작으면 학습이 제대로 이루어지지 않음\n",
    "##### 0.1 ~ 0.01 전후로 시도하며 조정해야함(손실함수값이 커지는 오버슈팅에 주의)\n",
    "\n",
    "\n",
    "gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "##### train에 저장되어 있는 GradientDescentOptimizer함수를 통해 op를 만들고\n",
    "##### rmse를 줄이는 목적을 위해 optimizer의 minimize를 호출시켜 줄이고자하는 값 rmse를 전달\n",
    "\n",
    "with tf.Session() as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001) :\n",
    "        sess.run(gradient_descent)\n",
    "        \n",
    "        if step % 100 == 0 :\n",
    "            print (\"Epoch : %.f, RMSE = %.04f, 기울기 a = %.4f, y 절편 b = %.4f\"\n",
    "                  % (step, sess.run(RMSE), sess.run(a), sess.run(b))\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd826d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf 2.x\n",
    "import tensorflow as tf\n",
    "#####    로 바로 실행되며\n",
    "#####    1.x와 다르게 즉시실행을 기본으로하고 keras API를 기본으로 포함시킴\n",
    "### tensorboard를 통해 세션의 그래프를 볼수 있음\n",
    "    \n",
    "data = [[2,81], [4, 93], [6, 91], [4,97]]\n",
    "x_train = [x_row[0], for x_row in data]\n",
    "y_train = [y_row[1], for y_row in data]\n",
    "\n",
    "w = tf.Variable(tf.random.uniform([1], 0 , 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random.uniform([1], 0 , 100, dtype = tf.float64, seed = 0))\n",
    "\n",
    "def hypothesis(w,b) : \n",
    "    return x_train * w + b\n",
    "\n",
    "def costFunc() :\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(w,b) - y_train)))\n",
    "\n",
    "def cost(w,b) :\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(w,b) - y_train)))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
    "for i in range(2000) :\n",
    "    opt.minimize(costFunc, var_list=[w,b])\n",
    "    if i % 100 = 0 :\n",
    "        print(i, f'{cost(w,b)}, {w.numpy()}, {b.numpy()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c52a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#다중선형회귀\n",
    " - y = a * x_data + b 에서\n",
    " - y = a1 * x1 + a2 * x2 + b 로 상세 조건이 추가되는것 (공부시간 -> 공부시간, 과외횟수)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [4, 3, 97]]\n",
    "x1_data = [x_row[0], for x_row in data]\n",
    "####추가\n",
    "x2_data = [x_row[1], for x_row in data]\n",
    "y_data = [y_row[2], for y_row in data]\n",
    "\n",
    "a1 = tf.Variable(tf.random_uniform([1], 0 , 10, dtype = tf.float64, seed = 0))\n",
    "b = tf.Variable(tf.random_uniform([1], 0 , 100, dtype = tf.float64, seed = 0))\n",
    "####추가\n",
    "a2 = tf.Variable(tf.random_uniform([1], 0 , 10, dtype = tf.float64, seed = 0))\n",
    "\n",
    "y = a1 * x1 + a2 * x2 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  - 로지스틱회귀 : 참 거짓 중 하나를 추출하는 방법\n",
    "    - 시그모이드 함수를 통해 S자 형태 그래프를 그릴 수 있음\n",
    "                     -(ax + b)\n",
    "        y = 1 / 1 + e\n",
    "         - a 값이 커지면 경사가 커지고, a값이 작으면 경사가 작아짐\n",
    "             - a 가 작아지면 오차는 무한대로 커지지만, 커진다고해서 오차가 커지지는 않음\n",
    "         - b는 그래프의 좌우 이동\n",
    "    \n",
    "    -  y = -loga X 와        y = -loga(1-X)의 그래프를 활용\n",
    "         (실제값이 1일때)     (실제값이 0일때)\n",
    "         예측값이 0에 가까,   예측값이 1에 가까워지면 오차가 커져야함\n",
    "        if y = 1 ->  cost(H(x),y) = -log(H(x))\n",
    "        if y = 0 ->  cost(H(x),y) = -log(1-H(x))\n",
    "            \n",
    "      이러한 형태를 다음과 같이 변형하여 표현          \n",
    "        cost(H(x),y) = -[ylogH(x) + (1-y)log(1-H(x))]  \n",
    "                         ---A---    -------B-------\n",
    "            실제 값 y 가 1이면 B가없어지고, 0 이면 A가 없어짐\n",
    "            경사하강법을 통해 그래프화 및 값 출력이 가능해짐\n",
    "            \n",
    "            \n",
    "    - 시그모이드 방정식\n",
    "     y = 1/(1 + np.e**-(a * x_data + b ))\n",
    "     loss = - tf.reduce_mean(np.array(y_data) * tf.log(y) + \n",
    "                             (1 - np,array(y_data) * (tf.log( 1 - y))))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 로지스틱회귀 TF 2.x 버전\n",
    "def hypothesis(a,b) : \n",
    "    return 1 / (1 + np.e**-(a * x_data + b))\n",
    "def costFunc() :\n",
    "    return -tf.reduce_mean(np.array(y_data) * tf.math.log(hypothesis(a,b))\n",
    "                           + ( 1 - np.array(y_data)) * tf.math.log(hypothesis(a,b)))\n",
    "\n",
    "def cost(a,b) :\n",
    "    return -tf.reduce_mean(np.array(y_data) * tf.math.log(hypothesis(a,b))\n",
    "                           + ( 1 - np.array(y_data)) * tf.math.log(hypothesis(a,b)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc622db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be3d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedbd33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
